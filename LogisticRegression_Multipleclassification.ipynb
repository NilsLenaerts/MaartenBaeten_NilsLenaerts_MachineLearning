{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/nils/Documents/school/schooljaar-2022_2023/MACLE_4483/MaartenBaeten_NilsLenaerts_MachineLearning/Data/dice-d4-d6-d8-d10-d12-d20/dice/train\\\\d12'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 264\u001b[0m\n\u001b[1;32m    261\u001b[0m     pred \u001b[39m=\u001b[39m predictOneVsAll(all_theta, X)\n\u001b[1;32m    262\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining Set Accuracy: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(np\u001b[39m.\u001b[39mmean(pred \u001b[39m==\u001b[39m y) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m))\n\u001b[0;32m--> 264\u001b[0m main()\n",
      "Cell \u001b[0;32mIn [1], line 239\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m--> 239\u001b[0m     gray_arrays, labels_int,j \u001b[39m=\u001b[39m loadData(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/home/nils/Documents/school/schooljaar-2022_2023/MACLE_4483/MaartenBaeten_NilsLenaerts_MachineLearning/Data/dice-d4-d6-d8-d10-d12-d20/dice/train\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    240\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinnished loading data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    241\u001b[0m     X_t \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([np\u001b[39m.\u001b[39mones((X_size, \u001b[39m1\u001b[39m)), gray_arrays], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn [1], line 203\u001b[0m, in \u001b[0;36mloadData\u001b[0;34m(directory_path)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mfor\u001b[39;00m directory \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(directory_path):\n\u001b[1;32m    202\u001b[0m     newPath \u001b[39m=\u001b[39m directory_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m directory\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(newPath):\n\u001b[1;32m    204\u001b[0m         \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(ext):\n\u001b[1;32m    205\u001b[0m             path \u001b[39m=\u001b[39m newPath \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m file\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/nils/Documents/school/schooljaar-2022_2023/MACLE_4483/MaartenBaeten_NilsLenaerts_MachineLearning/Data/dice-d4-d6-d8-d10-d12-d20/dice/train\\\\d12'"
     ]
    }
   ],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm \n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "from scipy import misc\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils\n",
    "\n",
    "# importing os module \n",
    "import os \n",
    "\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\"\"\"\n",
    "Computes the cost of using theta as the parameter for regularized\n",
    "logistic regression and the gradient of the cost w.r.t. to the parameters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "theta : array_like\n",
    "    Logistic regression parameters. A vector with shape (n, ). n is \n",
    "    the number of features including any intercept.  \n",
    "\n",
    "X : array_like\n",
    "    The data set with shape (m x n). m is the number of examples, and\n",
    "    n is the number of features (including intercept).\n",
    "\n",
    "y : array_like\n",
    "    The data labels. A vector with shape (m, ).\n",
    "\n",
    "lambda_ : float\n",
    "    The regularization parameter. \n",
    "\n",
    "Returns\n",
    "-------\n",
    "J : float\n",
    "    The computed value for the regularized cost function. \n",
    "\n",
    "grad : array_like\n",
    "    A vector of shape (n, ) which is the gradient of the cost\n",
    "    function with respect to theta, at the current values of theta.   \n",
    "\"\"\"\n",
    "def lrCostFunction(theta, X, y, lambda_):\n",
    "    #Initialize some useful values\n",
    "    m = y.size\n",
    "    # convert labels to ints if their type is bool\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "    \n",
    "    J=(1/m) * ((-y.dot(np.log(h)))-(1-y).dot(np.log(1-h)))+ ((lambda_/(2*m))* np.sum(np.square(temp)))\n",
    "    grad = (1 / m) * (h - y).dot(X) \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "    # =============================================================\n",
    "    return J, grad\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Trains num_labels logistic regression classifiers and returns\n",
    "each of these classifiers in a matrix all_theta, where the i-th\n",
    "row of all_theta corresponds to the classifier for label i.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "X : array_like\n",
    "    The input dataset of shape (m x n). m is the number of \n",
    "    data points, and n is the number of features. Note that we \n",
    "    do not assume that the intercept term (or bias) is in X, however\n",
    "    we provide the code below to add the bias term to X. \n",
    "\n",
    "y : array_like\n",
    "    The data labels. A vector of shape (m, ).\n",
    "\n",
    "num_labels : int\n",
    "    Number of possible labels.\n",
    "\n",
    "lambda_ : float\n",
    "    The logistic regularization parameter.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "all_theta : array_like\n",
    "    The trained parameters for logistic regression for each class.\n",
    "    This is a matrix of shape (K x n+1) where K is number of classes\n",
    "    (ie. `numlabels`) and n is number of features without the bias.\n",
    "\n",
    "\"\"\"\n",
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "\n",
    "    # Some useful variables\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # You need to return the following variables correctly \n",
    "    all_theta = np.zeros((num_labels, n + 1))#10x401\n",
    "\n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    #num_labels = 10 \n",
    "    #y = 5000, filled with 0s-9s\n",
    "    for c in range(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)#401 x 1\n",
    "        options = {'maxiter': 50}\n",
    "        res = optimize.minimize(lrCostFunction, \n",
    "                                initial_theta, \n",
    "                                (X, (y == c), lambda_), \n",
    "                                jac=True, \n",
    "                                method='CG',\n",
    "                                options=options) \n",
    "        all_theta[c] = res.x\n",
    "    # ============================================================\n",
    "    return all_theta    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return a vector of predictions for each example in the matrix X. \n",
    "Note that X contains the examples in rows. all_theta is a matrix where\n",
    "the i-th row is a trained logistic regression theta vector for the \n",
    "i-th class. You should set p to a vector of values from 0..K-1 \n",
    "(e.g., p = [0, 2, 0, 1] predicts classes 0, 2, 0, 1 for 4 examples) .\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "all_theta : array_like\n",
    "    The trained parameters for logistic regression for each class.\n",
    "    This is a matrix of shape (K x n+1) where K is number of classes\n",
    "    and n is number of features without the bias.\n",
    "\n",
    "X : array_like\n",
    "    Data points to predict their labels. This is a matrix of shape \n",
    "    (m x n) where m is number of data points to predict, and n is number \n",
    "    of features without the bias term. Note we add the bias term for X in \n",
    "    this function. \n",
    "\n",
    "Returns\n",
    "-------\n",
    "p : array_like\n",
    "    The predictions for each data point in X. This is a vector of shape (m, ).\n",
    "\n",
    "\"\"\"\n",
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    # ============================================================\n",
    "    return p\n",
    "\n",
    "\n",
    "X_size = 14284 #2046 validation 14284 train 2039 valid which are 691200 and 14284 which are 691200 \n",
    "Gray_size = 57600  #230400\n",
    "\n",
    "def loadData(directory_path):\n",
    "    labels_int = np.zeros((X_size))\n",
    "    gray_arrays = np.zeros((X_size,Gray_size))\n",
    "    directory_path\n",
    "    ext = ('.jpg')\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for directory in os.listdir(directory_path):\n",
    "        newPath = directory_path + '/' + directory\n",
    "        for file in os.listdir(newPath):\n",
    "            if file.endswith(ext):\n",
    "                path = newPath + '/' + file\n",
    "\n",
    "                img = io.imread(path)\n",
    "                if(img.size == 691200):\n",
    "                    imgGray = color.rgb2gray(img)\n",
    "                    res_img = rescale(imgGray, 0.5, anti_aliasing=False)\n",
    "                    imgn = np.reshape(res_img,(1,Gray_size),order='F')\n",
    "                    gray_arrays[i] = imgn\n",
    "                    type = directory\n",
    "                    match type:\n",
    "                        case 'd4':\n",
    "                            labels_int[i]=0\n",
    "                        case 'd6':\n",
    "                            labels_int[i]=1\n",
    "                        case 'd8':\n",
    "                            labels_int[i]=2\n",
    "                        case 'd10':\n",
    "                            labels_int[i]=3\n",
    "                        case 'd12':\n",
    "                            labels_int[i]=4\n",
    "                        case 'd20':\n",
    "                            labels_int[i]=5   \n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                i = i + 1   \n",
    "                j=j+1                                                                                                                \n",
    "            else:\n",
    "                continue\n",
    "    i = 0\n",
    "\n",
    "    return gray_arrays, labels_int,j\n",
    "  \n",
    "def main():\n",
    "    gray_arrays, labels_int,j = loadData(r\"/home/nils/Documents/school/schooljaar-2022_2023/MACLE_4483/MaartenBaeten_NilsLenaerts_MachineLearning/Data/dice-d4-d6-d8-d10-d12-d20/dice/train\")\n",
    "    print(\"finnished loading data\")\n",
    "    X_t = np.concatenate([np.ones((X_size, 1)), gray_arrays], axis=1)\n",
    "    # print(X_t)\n",
    "    X = X_t\n",
    "    y_t = labels_int\n",
    "    y = labels_int\n",
    "\n",
    "    num_labels = 6\n",
    "\n",
    "    # test values for the parameters theta\n",
    "    theta_t = np.zeros(57601 )\n",
    "\n",
    "    # test value for the regularization parameter\n",
    "    lambda_t = 0.001\n",
    "\n",
    "    J, grad = lrCostFunction(theta_t, X_t, y_t, lambda_t)\n",
    "    print('Cost         : {:.6f}'.format(J))\n",
    "    print(' [{:.6f}, {:.6f}, {:.6f}, {:.6f}]'.format(*grad))\n",
    "\n",
    "    lambda_ = 0.001\n",
    "    all_theta = oneVsAll(X, y, num_labels, lambda_)\n",
    "    pred = predictOneVsAll(all_theta, X)\n",
    "    print('Training Set Accuracy: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
