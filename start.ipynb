{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=float64), array([], dtype=float64), 14284)\n"
     ]
    }
   ],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm \n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "from scipy import misc\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils\n",
    "\n",
    "# importing os module \n",
    "import os \n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Computes the cost of using theta as the parameter for regularized\n",
    "logistic regression and the gradient of the cost w.r.t. to the parameters.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "theta : array_like\n",
    "    Logistic regression parameters. A vector with shape (n, ). n is \n",
    "    the number of features including any intercept.  \n",
    "\n",
    "X : array_like\n",
    "    The data set with shape (m x n). m is the number of examples, and\n",
    "    n is the number of features (including intercept).\n",
    "\n",
    "y : array_like\n",
    "    The data labels. A vector with shape (m, ).\n",
    "\n",
    "lambda_ : float\n",
    "    The regularization parameter. \n",
    "\n",
    "Returns\n",
    "-------\n",
    "J : float\n",
    "    The computed value for the regularized cost function. \n",
    "\n",
    "grad : array_like\n",
    "    A vector of shape (n, ) which is the gradient of the cost\n",
    "    function with respect to theta, at the current values of theta.   \n",
    "\"\"\"\n",
    "def lrCostFunction(theta, X, y, lambda_):\n",
    "    #Initialize some useful values\n",
    "    m = y.size\n",
    "    # convert labels to ints if their type is bool\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    h = utils.sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "    \n",
    "    J=(1/m) * ((-y.dot(np.log(h)))-(1-y).dot(np.log(1-h)))+ ((lambda_/(2*m))* np.sum(np.square(temp)))\n",
    "    grad = (1 / m) * (h - y).dot(X) \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "    # =============================================================\n",
    "    return J, grad\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Trains num_labels logistic regression classifiers and returns\n",
    "each of these classifiers in a matrix all_theta, where the i-th\n",
    "row of all_theta corresponds to the classifier for label i.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "X : array_like\n",
    "    The input dataset of shape (m x n). m is the number of \n",
    "    data points, and n is the number of features. Note that we \n",
    "    do not assume that the intercept term (or bias) is in X, however\n",
    "    we provide the code below to add the bias term to X. \n",
    "\n",
    "y : array_like\n",
    "    The data labels. A vector of shape (m, ).\n",
    "\n",
    "num_labels : int\n",
    "    Number of possible labels.\n",
    "\n",
    "lambda_ : float\n",
    "    The logistic regularization parameter.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "all_theta : array_like\n",
    "    The trained parameters for logistic regression for each class.\n",
    "    This is a matrix of shape (K x n+1) where K is number of classes\n",
    "    (ie. `numlabels`) and n is number of features without the bias.\n",
    "\n",
    "\"\"\"\n",
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "\n",
    "    # Some useful variables\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # You need to return the following variables correctly \n",
    "    all_theta = np.zeros((num_labels, n + 1))#10x401\n",
    "\n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    #num_labels = 10 \n",
    "    #y = 5000, filled with 0s-9s\n",
    "    for c in range(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)#401 x 1\n",
    "        options = {'maxiter': 50}\n",
    "        res = optimize.minimize(lrCostFunction, \n",
    "                                initial_theta, \n",
    "                                (X, (y == c), lambda_), \n",
    "                                jac=True, \n",
    "                                method='CG',\n",
    "                                options=options) \n",
    "        all_theta[c] = res.x\n",
    "    # ============================================================\n",
    "    return all_theta    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Return a vector of predictions for each example in the matrix X. \n",
    "Note that X contains the examples in rows. all_theta is a matrix where\n",
    "the i-th row is a trained logistic regression theta vector for the \n",
    "i-th class. You should set p to a vector of values from 0..K-1 \n",
    "(e.g., p = [0, 2, 0, 1] predicts classes 0, 2, 0, 1 for 4 examples) .\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "all_theta : array_like\n",
    "    The trained parameters for logistic regression for each class.\n",
    "    This is a matrix of shape (K x n+1) where K is number of classes\n",
    "    and n is number of features without the bias.\n",
    "\n",
    "X : array_like\n",
    "    Data points to predict their labels. This is a matrix of shape \n",
    "    (m x n) where m is number of data points to predict, and n is number \n",
    "    of features without the bias term. Note we add the bias term for X in \n",
    "    this function. \n",
    "\n",
    "Returns\n",
    "-------\n",
    "p : array_like\n",
    "    The predictions for each data point in X. This is a vector of shape (m, ).\n",
    "\n",
    "\"\"\"\n",
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    p = utils.sigmoid(X.dot(all_theta.T))\n",
    "    \n",
    "    # Adding one because Python uses zero based indexing for the 10 columns (0-9),\n",
    "    # while the 10 classes are numbered from 1 to 10.\n",
    "    return(np.argmax(p, axis=1))\n",
    "    # ============================================================\n",
    "    return p\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Loads the img and converts it into an array, then converts it into a gray scale array\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "path : string\n",
    "    The path including the img to the image needing to be converted\n",
    "\n",
    "Returns\n",
    "-------   \n",
    "gray_array : array_like\n",
    "    An array with the gray scale value of the pixels\n",
    "\"\"\"\n",
    "def img2gray(path):\n",
    "    img_array = mpimg.imread(path)  \n",
    "    red=img_array[:,:,0]\n",
    "    green=img_array[:,:,1]\n",
    "    blue=img_array[:,:,2]\n",
    "    gray_array = np.array([])\n",
    "    gray_array = np.append(gray_array, 0.2126 * red)\n",
    "    gray_array = np.append(gray_array, 0.7152 * green)\n",
    "    gray_array = np.append(gray_array, 0.0722 * blue)\n",
    "    # gray_array = (0.2126 * red) + (0.7152 * green) + (0.0722 * blue) \n",
    "    # pyplot.imshow(gray_array, cmap = pyplot.cm.Greys_r)\n",
    "    # pyplot.show() \n",
    "    return gray_array\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Loads the all the images and ad label of die type as a tuple together with the grayscale image \n",
    "Then add it into a array\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "path : string\n",
    "    The path to the dataset\n",
    "\n",
    "Returns\n",
    "-------   \n",
    "dice : array_like\n",
    "    array of tuples, each tupple contains a string (label) of which type of die it is, and a grayscale image array (which is an array of arrays)\n",
    "\n",
    "labels :\n",
    "\"\"\"\n",
    "def loadData(path):\n",
    "    labels_int = np.array([])\n",
    "    i = 0\n",
    "    gray_arrays = np.array([])\n",
    "    path_of_the_directory = path\n",
    "    ext = ('.jpg')\n",
    "    for directory in os.listdir(path_of_the_directory):\n",
    "        newPath = path_of_the_directory + '\\\\' + directory\n",
    "        for file in os.listdir(newPath):\n",
    "            if file.endswith(ext):\n",
    "                path = newPath + '\\\\' + file\n",
    "                # img = img2gray(path)\n",
    "                type = directory\n",
    "                # gray_arrays = np.append(gray_arrays,img,axis = 0)\n",
    "                i = i + 1\n",
    "                # np.append(dice,img_tuple)\n",
    "                # np.append(labels,type)\n",
    "                # match type:\n",
    "                #     case 'd4':\n",
    "                #         labels_int = np.append(labels_int,0)\n",
    "                #         # labels_int.append(0)\n",
    "                #     case 'd6':\n",
    "                #         labels_int = np.append(labels_int,1)\n",
    "                #         # labels_int.append(1)\n",
    "                #     case 'd8':\n",
    "                #         labels_int = np.append(labels_int,2)\n",
    "                #         # labels_int.append(2)\n",
    "                #     case 'd10':\n",
    "                #         labels_int = np.append(labels_int,3)\n",
    "                #         # labels_int.append(3)\n",
    "                #     case 'd12':\n",
    "                #         labels_int = np.append(labels_int,4)\n",
    "                #         # labels_int.append(4)\n",
    "                #     case 'd20':\n",
    "                #         labels_int = np.append(labels_int,5)\n",
    "                #         # labels_int.append(5)                                                                                                                        \n",
    "            else:\n",
    "                continue\n",
    "    # tuple = dice[2030]\n",
    "    # tuple_label = tuple[0]\n",
    "    # tuple_grayimg = tuple[1]\n",
    "    # print(dice)\n",
    "    # print(tuple_label)\n",
    "    # print(len(dice)) # = 14284\n",
    "    # pyplot.imshow(tuple_grayimg, cmap = pyplot.cm.Greys_r)\n",
    "    # pyplot.show() \n",
    "    # print(labels)\n",
    "    return gray_arrays, labels_int,i\n",
    "\n",
    "  \n",
    "def main():\n",
    "    # img = img2gray(\"d4_angle_color000.jpg\") \n",
    "    # print(img)\n",
    "    # print(img.size)\n",
    "    i = loadData(r\"C:\\Users\\maart\\Documents\\IIW\\Machine\\Taak\\Data\\dice-d4-d6-d8-d10-d12-d20\\dice\\train\")\n",
    "    \n",
    "    # print(labels_int)\n",
    "    print(i)\n",
    "    # test values for the parameters theta\n",
    "    # theta_t = np.array([-2, -1, 1, 2], dtype=float)\n",
    "    # # test value for the regularization parameter\n",
    "    # lambda_t = 3\n",
    "\n",
    "    # J, grad = lrCostFunction(theta_t, gray_arrays, labels_int, lambda_t)\n",
    "\n",
    "    # lambda_ = 0.1\n",
    "    # num_labels = 6\n",
    "    # all_theta = oneVsAll(gray_arrays, labels_int, num_labels, lambda_)\n",
    "    # print(all_theta.shape)\n",
    "\n",
    "    # pred = predictOneVsAll(all_theta, dice)\n",
    "    # print('Training Set Accuracy: {:.2f}%'.format(np.mean(pred == labels_int) * 100))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19f9ddf3622c0b1569490fd927172cf777b9021a692f6f37361c5e5933f47574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
