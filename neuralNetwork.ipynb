{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm \n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "from scipy import misc\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# library written for this exercise providing additional functions for assignment submission, and others\n",
    "import utils\n",
    "# importing os module \n",
    "import os \n",
    "\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "    \n",
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    # You need to return the following variables correctly \n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "    # ============================================================\n",
    "    return W\n",
    "\n",
    "\n",
    "def sigmoidGradient(z):\n",
    "    g = np.zeros(z.shape)\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    g = sigmoid(z) * (1-  sigmoid(z))\n",
    "    # =============================================================\n",
    "    return g\n",
    "\n",
    "def nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_=0.0):\n",
    "\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    a1 = np.concatenate([np.ones((m,1)),X],axis = 1)\n",
    "    a2 =  sigmoid(a1.dot(Theta1.T))\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0],1)),a2],axis=1)\n",
    "    a3 =  sigmoid(a2.dot(Theta2.T))\n",
    "\n",
    "    y_matrix = y.reshape(-1)\n",
    "    y_matrix = np.eye(num_labels)[y_matrix].astype(int)\n",
    "\n",
    "    temp1 = Theta1\n",
    "    temp2 = Theta2\n",
    "\n",
    "    reg = (lambda_ / (2*m)) * (np.sum(np.square(temp1[:,1:])) + np.sum(np.square(temp2[:,1:])))\n",
    "    J = (-1/m) * np.sum((np.log(a3) * y_matrix) + np.log(1-a3) * (1-y_matrix)) + reg\n",
    "    \n",
    "    delta_3 = a3 - y_matrix\n",
    "    delta_2 = delta_3.dot(Theta2)[:,1:] * sigmoidGradient(a1.dot(Theta1.T))\n",
    "\n",
    "    Delta1 = delta_2.T.dot(a1)\n",
    "    Delta2 = delta_3.T.dot(a2)\n",
    "\n",
    "    Theta1_grad = (1/m) * Delta1\n",
    "    Theta1_grad[:,1:] = Theta1_grad[:,1:] + (lambda_ / m) * Theta1[:,1:]\n",
    "\n",
    "    Theta2_grad = (1/m) * Delta2\n",
    "    Theta2_grad[:,1:] = Theta2_grad[:,1:] + (lambda_ / m) * Theta2[:,1:]\n",
    "    \n",
    "    # ================================================================\n",
    "    # Unroll gradients\n",
    "    # grad = np.concatenate([Theta1_grad.ravel(order=order), Theta2_grad.ravel(order=order)])\n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "\n",
    "    return J, grad\n",
    "\n",
    "\n",
    "\n",
    "X_size = 14284 #2046 validation 14284 train 2039 valid which are 691200 and 14284 which are 691200 \n",
    "Gray_size = 57600  #230400\n",
    "\n",
    "def loadData(directory_path):\n",
    "    labels = np.zeros((X_size))\n",
    "    gray_arrays = np.zeros((X_size,Gray_size))\n",
    "    directory_path\n",
    "    ext = ('.jpg')\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for directory in os.listdir(directory_path):\n",
    "        newPath = directory_path + '/' + directory\n",
    "        for file in os.listdir(newPath):\n",
    "            if file.endswith(ext):\n",
    "                path = newPath + '/' + file\n",
    "\n",
    "                img = io.imread(path)\n",
    "                if(img.size == 691200):\n",
    "                    imgGray = color.rgb2gray(img)\n",
    "                    res_img = rescale(imgGray, 0.5, anti_aliasing=False)\n",
    "                    imgn = np.reshape(res_img,(1,Gray_size),order='F')\n",
    "                    gray_arrays[i] = np.float32(imgn)\n",
    "                    type = directory\n",
    "                    match type:\n",
    "                        case 'd4':\n",
    "                            labels[i]=int(0)\n",
    "                        case 'd6':\n",
    "                            labels[i]=int(1)\n",
    "                        case 'd8':\n",
    "                            labels[i]=int(2)\n",
    "                        case 'd10':\n",
    "                            labels[i]=int(3)\n",
    "                        case 'd12':\n",
    "                            labels[i]=int(4)\n",
    "                        case 'd20':\n",
    "                            labels[i]=int(5) \n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                i = i + 1   \n",
    "                j=j+1                                                                                                                \n",
    "            else:\n",
    "                continue\n",
    "    i = 0\n",
    "\n",
    "    return gray_arrays, labels,j\n",
    "\n",
    "def main():\n",
    "    gray_arrays, labels,j = loadData(r\"Data/dice-d4-d6-d8-d10-d12-d20/dice/train\")\n",
    "    X_t = np.concatenate([np.ones((X_size, 1)), gray_arrays], axis=1)\n",
    "    # print(X_t)\n",
    "\n",
    "    labels_int = labels.astype(int)\n",
    "    X = X_t\n",
    "    y_t = labels_int\n",
    "    y = labels_int\n",
    "    print(y)\n",
    "    # Setup the parameters you will use for this exercise\n",
    "    input_layer_size  = 57601  # Input Images of Digits\n",
    "    hidden_layer_size = 25   # 25 hidden units\n",
    "    num_labels = 6         # 10 labels, from 0 to 9\n",
    "\n",
    "    print('Initializing Neural Network Parameters ...')\n",
    "    initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "    initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "\n",
    "    # Unroll parameters\n",
    "    initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)\n",
    "    nn_params = initial_nn_params\n",
    "\n",
    "\n",
    "    # utils.checkNNGradients(nnCostFunction)\n",
    "\n",
    "    #  Check gradients by running checkNNGradients\n",
    "    lambda_ = 0.01\n",
    "    # utils.checkNNGradients(nnCostFunction, lambda_)\n",
    "\n",
    "    # Also output the costFunction debugging values\n",
    "    debug_J, _  = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\n",
    "\n",
    "    print('\\n\\nCost at (fixed) debugging parameters (w/ lambda = %f): %f ' % (lambda_, debug_J))\n",
    "    print('(for lambda = 3, this value should be about 0.576051)')\n",
    "\n",
    "        #  After you have completed the assignment, change the maxiter to a larger\n",
    "    #  value to see how more training helps.\n",
    "    options= {'maxiter': 100}\n",
    "\n",
    "    #  You should also try different values of lambda\n",
    "    lambda_ = 0.01\n",
    "\n",
    "    # Create \"short hand\" for the cost function to be minimized\n",
    "    costFunction = lambda p: nnCostFunction(p, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_)\n",
    "\n",
    "    # Now, costFunction is a function that takes in only one argument\n",
    "    # (the neural network parameters)\n",
    "    res = optimize.minimize(costFunction, initial_nn_params, jac=True, method='TNC', options=options)\n",
    "\n",
    "    # get the solution of the optimization\n",
    "    nn_params = res.x\n",
    "            \n",
    "    # Obtain Theta1 and Theta2 back from nn_params\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "    \n",
    "    pred = utils.predict(Theta1, Theta2, X)\n",
    "    print('Training Set Accuracy: %f' % (np.mean(pred == y) * 100))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
